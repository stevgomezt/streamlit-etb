# -*- coding: utf-8 -*-
"""Validar_Preprocesar_Predecir_OrganizarRtados

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jTjEBlMTSlSewFoTV610j2bB72qfxIWJ
"""

# Emergia/Mayo/15/2023
# LSCV

import numpy as np
import pandas as pd
import joblib	    # Para carga de modelo
from datetime import datetime
from sklearn.utils.extmath import row_norms
import plotly.graph_objects as go
import pytz


class Modelos_2():

    """ Clase para preprocesar los datos y con ellos ejecutar los modelos de ML pertinentes.
        Ademas Tambien organiza los resultados arrojados por el modelo. 
        Realiza graficos de torta
        Crea los logs de validación
    """

    def __init__(self, df_in):
        self.df_in = df_in

    def transform_load(self):  # todo a mayuscula y tranformar tipos de datos a los requeridos
        df = self.df_in.copy()
        df.columns = df.columns.str.normalize('NFKD').str.encode(
            'ascii', errors='ignore').str.decode('utf-8')
        df.columns = df.columns.str.upper().str.replace(
            ' ', '').str.replace('.', '', regex=False)

        # try:
        #   df['NUMERODEEMPLEADOS'] = df['NUMERODEEMPLEADOS'].astype(int)
        # except:
        # pass
        try:
            df['FECHACONSTITUCION'] = df['FECHACONSTITUCION'].astype(
                'datetime64[ns]')
            # df['NUMERODEEMPLEADOS']=df['NUMERODEEMPLEADOS'].astype('int64')
        except:
            pass

        cols_cat = df.dtypes[df.dtypes != 'int64'][df.dtypes != 'int'][df.dtypes !=
                                                                       'float'][df.dtypes != 'datetime64[ns]'].index.tolist()
        # print(cols_cat)
        df[cols_cat] = df[cols_cat].astype(str).apply(lambda x: x.str.normalize(
            'NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8'))
        df[cols_cat] = df[cols_cat].astype(str).apply(
            lambda x: x.str.upper().str.replace(' ', '').str.replace('.', '', regex=False))

        df['CONSPROM'] = df['CONSPROM'].fillna(0)
        df_con_nulls = df.copy()
        df_con_nulls.replace({'NAN': np.nan}, inplace=True)
        # df = df.dropna().reset_index(drop=True)
        lista_campos = []
        for co_e in df.columns:
            if co_e in ['NIT9', 'CONSPROM', 'NUMERODEEMPLEADOS', 'TOTALINGRESOOPERATIVO', 'TAMANOEMPRESA', 'GANANCIASDESPUESDEIMPUESTOS', 'ACTIVOSTOTALES', 'TOTALDEPATRIMONIO',
                        'FORMALEGAL', 'FECHACONSTITUCION', 'ACTIVIDADES',
                        # Variables descriptiva
                        'RANGOCONSUMO', 'RANGODECOMPRA($)', 'RANGORECURRENCIACOMPRA', 'TIPOCLIENTE#OPORTUNIDADES', 'CATEGORIZACIONSECTORES', 'CATEGORIADEPARTAMENTO', 'OPORTUNIDADESVENDIDAS', 'OPORTUNIDADESCOTIZADAS($)']:
                lista_campos.append(co_e)

        df = self.eliminar_registros_vacios(df, lista_campos)

        # df = df.reset_index(drop=True)

        for index, row in df[lista_campos].iterrows():
            # Verifica si algún campo contiene el string 'NAN'
            if 'NAN' in row.values:
                # print(row.values)
                # Elimina el registro correspondiente
                df = df.drop(index)

        # Reinicia los índices del dataframe resultante
        # df = df.reset_index(drop=True)

        return df, df_con_nulls

    # todo a mayuscula y tranformar tipos de datos a los requeridos
    def transform_load_graf(self):
        df = self.df_in.copy()
        df.columns = df.columns.str.normalize('NFKD').str.encode(
            'ascii', errors='ignore').str.decode('utf-8')
        df.columns = df.columns.str.upper().str.replace(
            ' ', '').str.replace('.', '', regex=False)

        try:
            df['NUMERODEEMPLEADOS'] = df['NUMERODEEMPLEADOS'].astype(int)

        except:
            pass
        try:
            df['FECHACONSTITUCION'] = df['FECHACONSTITUCION'].astype(
                'datetime64[ns]')
            # df['NUMERODEEMPLEADOS']=df['NUMERODEEMPLEADOS'].astype('int64')
        except:
            pass

        cols_cat = df.dtypes[df.dtypes != 'int64'][df.dtypes !=
                                                   'float'][df.dtypes != 'datetime64[ns]'].index.tolist()
        # print(cols_cat)
        df[cols_cat] = df[cols_cat].apply(lambda x: x.str.normalize(
            'NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8'))
        # df[cols_cat] = df[cols_cat].apply(lambda x: x.str.upper().str.replace(' ','').str.replace('.','',regex=False))

        return df

    def eliminar_registros_vacios(self, dataframe, campos):
        # Crea una copia del dataframe original
        df = dataframe.copy()

        # Itera sobre los campos proporcionados
        for campo in campos:
            # Elimina los registros que tengan campos vacíos en el campo actual
            df = df.dropna(subset=[campo])

        # Devuelve el dataframe sin los registros vacíos
        return df

    # CALCULO LA EDAD DE LAS EMPRESAS
    def Ano(self, df):
        s = df.year
        return s

    def extraer_ano(self, df):
        print("flag fecha")
        df['FECHACONSTITUCION'] = pd.to_datetime(
            df['FECHACONSTITUCION'], errors='coerce')  # , format='%d/%m/%Y'
        df['EDAD'] = datetime.now().year - df['FECHACONSTITUCION'].dt.year

        return df

    def sectores(self, df, lista, sector):
        for i in lista:
            if i in df:
                return sector

    def Agrupar_actividades(self, Act_CIIU='ACTIVIDADPRINCIPAL(EMIS)'):  # IMPORTANTE

        df_a, df_con_nulls = self.transform_load()
        # print(df_a)
        # # Diccionario Actividades Econmicas
        actividad = ['SIN ACTIVIDAD']
        agro = ['CULTIVO', 'CRIA', 'PROPAGACION', 'PLANTAS', 'DESCAFEINADO', 'AGRICOLA', 'PECUARIA', 'AGRICOLA', 'CULTIVOS',
                'GANADERIA', 'GANADO', 'CORRAL', 'ANIMALES', 'AGRICULTURA', 'CAFE']  # 'Agropecuario'

        servicios = ['PREPARADAS', 'ARRENDADOS', 'ALOJAMIENTO', 'CENTROS', 'LLAMADAS', 'HOSPITALES', 'CLINICAS', 'CONSULTORIA', 'INSTALACIONES',
                     'PROGRAMACION', 'TELEVISION', 'RADIO', 'RADIODIFUSION', 'INMOBILIARIAS',  'SERVICIO', 'DISTRIBUCION', 'AGUA',
                     'PUBLICIDAD', 'AUXILIARES', 'IMPRESION', 'APOYO', 'DIAGNOSTICO', 'INVESTIGACIONES', 'COMIDAS',
                     'COMERCIALES', 'LIBROS', 'MUSICALES', 'PROFESIONALES', 'MEDICA', 'MANTENIMIENTO', 'CINEMATOGRAFICAS',
                     'NIVELES', 'ADMINISTRACION', 'SALUD', 'PARQUES', 'TEMATICOS', 'RECOLECCION', 'SISTEMAS', 'INFORMATICOS',
                     'PROCESAMIENTO DE DATOS', 'OTRAS ASOCIACIONES', 'ENSAYOS', 'ESTUDIOS DE MERCADO', 'RECREATIVAS', 'CLUBES DEPORTIVOS',
                     'CONSULTARIA DE GESTION', 'RESIDUALES', 'ATRACCIONES', 'INGENIERIA', 'ASOCIACIONES', 'CLUBES', 'LIBROS', 'TALENTO',
                     'RECREATIVAS', 'AGUA', 'MEDICA', 'PELUQUERIA',
                     'UNIVERSIDADES',  'COMUNIDADES', 'EVACUACION', 'RECUPERACION',  'REPARACION', 'ALOJAMIENTO',
                     'EXPENDIO', 'EVENTOS', 'EDICION',  'EMPRESARIAL', 'GESTION', 'CIENTIFICAS',
                     'VIAJE', 'SEGURIDAD', 'OFICINA', 'EMPRESAS', 'SOCIAL', 'INSTITUCIONES', 'SEGURIDAD', 'EDUCACION', 'EDUCACION', 'SALUD',
                     'MEDICA', 'TERAPEUTICO', 'APUESTAS', 'CLUBES', 'RECREATIVAS', 'ASOCIACIONES', 'SERVICIOS', 'ORGANIZACIONES',
                     'EDUCACION', 'ASOCIACIONES',  'ENVASE', 'FOTOGRAFIA', 'SOCIA', 'SEGURIDAD', 'COMIDAS', 'DISENO',
                     'JURIDICAS', 'PROFESIONALES', 'ALQUILER', 'ASERRADO', 'TALLADO', 'CURTIDO', 'ELECTRONICA', 'HOTELES',
                     'EMPRESARIAL', 'CARGA',  'ASISTENCIA', 'SERVICIOS', 'FUNEBRES', 'RECUPERACION', 'ACONDICIONADO', 'TRATAMIENTO',
                     'TURISMO', 'ORGANIZACIONES', 'ESTUDIOS']  # 'Servicios'

        industrial = ['ELABORACION', 'FABRICACION', 'INDUSTRIAS', 'PROCESAMIENTO', 'TEXTILES', 'CONFECCION', 'FUNDICION', 'DERIVADOS DEL CAFE',
                      'DESTILACION', 'EMPRESARIAL', 'MAQUINARIA', 'MAQUINARIA', 'CARNE', 'PESCADOS', 'FRUTAS', 'ACEITES', 'LACTEOS', 'MOLINERIA',
                      'PANADERIA', 'ALIMENTICIOS', 'PREPARADOS', 'CERVEZAS', 'HILATURA', 'TEJEDURIA', 'TEXTILES', 'CONFECCION', 'FABRICACION',
                      'INDUSTRIAS', 'FUNDICION', 'MAQUINARIA', 'CARNES', 'METAL', 'QUIMICA']  # 'Industrial'

        transporte = ['TRANSPORTE', 'AEROPUERTOS', 'ALMACENAMIENTO Y DEPOSITO',
                      'TRANSPORTE', 'TRANSPORTE']  # Transporte
        comercio = ['COMERCIO', 'COMERCIALIZACION', 'COMERCIO',
                    'COMERCIAL', 'ALIMENTOS', 'AUTOMOTRIZ']  # Comercio

        financiero = ['CAPITAL', 'VALORES', 'BANCOS', 'BANCA', 'SERVICIO FINANCIERO', 'FINANCIERAS', 'COMPANIAS DE FINANCIAMIENTO',
                      'FONDOS', 'BANCO', 'FINANCIERAS', 'FINANCIERO', 'FONDOS', 'SEGUROS', 'VALORES', 'FONDOS', 'SEGUROS', 'SEGUROS']  # Financiero

        const = ['EDIFICIOS', 'CONSTRUCCION', 'ARQUITECTURA', 'CONSTRUCCION',
                 'DEMOLICION', 'EDIFICIOS', 'CONSTRUCCION']  # Construcción
        minero = ['GAS', 'CARBON', 'EXTRACCION', 'GENERACION', 'TRANSMISION', 'CARBON', 'ORO', 'MINERALES', 'PIEDRA',
                  'ESMERALDAS', 'PETROLEO', 'ENERGIA', 'MINERIA']  # Minero y Energético

        comunicaciones = ['TELECOMUNICACIONES', 'TELECOMUNICACIONES', 'TELECOMUNICACIONES', 'ALAMBRICAS', 'INALAMBRICAS',
                          'SATELITAL', 'TELECOMUNICACIONES']  # Comunicaciones

        df_a[Act_CIIU].replace(np.nan, 'SIN ACTIVIDAD', inplace=True)

        def n(x): return self.sectores(x, actividad, 'SIN ACTIVIDAD')
        s1 = pd.DataFrame(df_a[Act_CIIU].apply(n))
        df_a['ACTIVIDADES'] = s1

        def n(x): return self.sectores(x, servicios, 'SERVICIOS')
        s1 = pd.DataFrame(df_a[Act_CIIU].apply(n))
        ind = s1[~s1[Act_CIIU].isnull()].index
        df_a.loc[ind, 'ACTIVIDADES'] = s1.loc[ind, Act_CIIU]

        def n(x): return self.sectores(x, agro, 'AGROPECUARIO')
        s1 = pd.DataFrame(df_a[Act_CIIU].apply(n))
        ind = s1[~s1[Act_CIIU].isnull()].index
        df_a.loc[ind, 'ACTIVIDADES'] = s1.loc[ind, Act_CIIU]

        def n(x): return self.sectores(x, industrial, 'INDUSTRIAL')
        s1 = pd.DataFrame(df_a[Act_CIIU].apply(n))
        ind = s1[~s1[Act_CIIU].isnull()].index
        df_a.loc[ind, 'ACTIVIDADES'] = s1.loc[ind, Act_CIIU]

        def n(x): return self.sectores(x, transporte, 'TRANSPORTE')
        s1 = pd.DataFrame(df_a[Act_CIIU].apply(n))
        ind = s1[~s1[Act_CIIU].isnull()].index
        df_a.loc[ind, 'ACTIVIDADES'] = s1.loc[ind, Act_CIIU]

        def n(x): return self.sectores(x, comercio, 'COMERCIO')
        s1 = pd.DataFrame(df_a[Act_CIIU].apply(n))
        ind = s1[~s1[Act_CIIU].isnull()].index
        df_a.loc[ind, 'ACTIVIDADES'] = s1.loc[ind, Act_CIIU]

        def n(x): return self.sectores(x, financiero, 'FINANCIERO')
        s1 = pd.DataFrame(df_a[Act_CIIU].apply(n))
        ind = s1[~s1[Act_CIIU].isnull()].index
        df_a.loc[ind, 'ACTIVIDADES'] = s1.loc[ind, Act_CIIU]

        def n(x): return self.sectores(x, const, 'CONSTRUCCION')
        s1 = pd.DataFrame(df_a[Act_CIIU].apply(n))
        ind = s1[~s1[Act_CIIU].isnull()].index
        df_a.loc[ind, 'ACTIVIDADES'] = s1.loc[ind, Act_CIIU]

        def n(x): return self.sectores(x, minero, 'ENERGETICO')
        s1 = pd.DataFrame(df_a[Act_CIIU].apply(n))
        ind = s1[~s1[Act_CIIU].isnull()].index
        df_a.loc[ind, 'ACTIVIDADES'] = s1.loc[ind, Act_CIIU]

        def n(x): return self.sectores(x, comunicaciones, 'COMUNICACIONES')
        s1 = pd.DataFrame(df_a[Act_CIIU].apply(n))
        ind = s1[~s1[Act_CIIU].isnull()].index
        df_a.loc[ind, 'ACTIVIDADES'] = s1.loc[ind, Act_CIIU]

        df_a['ACTIVIDADES'].fillna('Actividad_Desconocida', inplace=True)
        return df_a

    def Encoder(self):  # ---------------------------------------------- ENCODER ---------------------------------------------
        df_tmp = self.Agrupar_actividades(
            'ACTIVIDADPRINCIPAL(EMIS)')  # Agrupar actividades
        # Calcular Edad
        df_tmp = self.extraer_ano(df_tmp)

        if datetime.now().month == 12:
            df_tmp['MES_OFERTA'] = 1
        else:
            df_tmp['MES_OFERTA'] = datetime.now().month+1

        df_tmp.reset_index(drop=True, inplace=True)
        self.df_in.reset_index(drop=True, inplace=True)
        print(f"el tamaño 1 es {len(df_tmp)} el dos {len(self.df_in)}")

        df_tmp = df_tmp[df_tmp['ACTIVIDADES'] != 'Actividad_Desconocida']
        # print('Actividad_NO_Desconocida shape',len(df_tmp))

        self.df_in = self.df_in.loc[df_tmp.index, :].merge(
            df_tmp[['NIT9', 'ACTIVIDADES']], on='NIT9', how='left')
        self.df_in.columns = self.df_in.columns.str.normalize(
            'NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')
        self.df_in.columns = self.df_in.columns.str.upper().str.replace(
            ' ', '').str.replace('.', '', regex=False)

        if 'CONSPROM' in df_tmp.columns:
            df_tmp = df_tmp[['NIT9', 'CONSPROM', 'NUMERODEEMPLEADOS', 'TOTALINGRESOOPERATIVO', 'TAMANOEMPRESA', 'GANANCIASDESPUESDEIMPUESTOS', 'ACTIVOSTOTALES', 'TOTALDEPATRIMONIO',
                             'FORMALEGAL', 'EDAD', 'MES_OFERTA', 'ACTIVIDADES']]
        else:
            df_tmp = df_tmp[['NIT9', 'NUMERODEEMPLEADOS', 'TOTALINGRESOOPERATIVO', 'TAMANOEMPRESA', 'GANANCIASDESPUESDEIMPUESTOS', 'ACTIVOSTOTALES', 'TOTALDEPATRIMONIO',
                             'FORMALEGAL', 'EDAD', 'MES_OFERTA', 'ACTIVIDADES']]

        columns1 = df_tmp.columns
        # print(columns1)

        columns_F = ['F0', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8']
        ord_F = ['SAS', 'LTDA', 'SA', 'ESAL', 'SUCURSALEXTRANJERA', 'SCA',
                 'UNDEFINED', 'SCS', 'PERSONANATURAL']

        columns_T = ['T0', 'T1', 'T2']
        ord_T = ['GRANEMPRESA', 'MEDIANAEMPRESA', 'PEQUENAEMPRESA']

        columns_M = ['M1', 'M2', 'M3', 'M4', 'M5',
                     'M6', 'M7', 'M8', 'M9', 'M10', 'M11', 'M12']
        ord_M = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0]

        columns_A = ['A0', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8']
        ord_A = ['AGROPECUARIO', 'COMERCIO', 'COMUNICACIONES', 'CONSTRUCCION',
                 'ENERGETICO', 'FINANCIERO', 'INDUSTRIAL', 'SERVICIOS', 'TRANSPORTE']

        columnas_totales = list(columns1) + columns_T + \
            columns_F + columns_A + columns_M  # columns_D +
        df_r = pd.DataFrame(columns=columnas_totales)

        if 'CONSPROM' in df_tmp.columns:
            df_r[['NIT9', 'NUMERODEEMPLEADOS', 'GANANCIASDESPUESDEIMPUESTOS', 'TOTALINGRESOOPERATIVO', 'ACTIVOSTOTALES', 'EDAD', 'MES_OFERTA', 'CONSPROM', 'ACTIVIDADES', 'TAMANOEMPRESA', 'FORMALEGAL', 'TOTALDEPATRIMONIO'
                  ]] = df_tmp[['NIT9', 'NUMERODEEMPLEADOS', 'GANANCIASDESPUESDEIMPUESTOS', 'TOTALINGRESOOPERATIVO', 'ACTIVOSTOTALES', 'EDAD', 'MES_OFERTA', 'CONSPROM', 'ACTIVIDADES', 'TAMANOEMPRESA', 'FORMALEGAL', 'TOTALDEPATRIMONIO']]
        else:
            df_r[['NIT9', 'NUMERODEEMPLEADOS', 'GANANCIASDESPUESDEIMPUESTOS', 'TOTALINGRESOOPERATIVO', 'ACTIVOSTOTALES', 'EDAD', 'MES_OFERTA', 'ACTIVIDADES', 'TAMANOEMPRESA', 'FORMALEGAL', 'TOTALDEPATRIMONIO'
                  ]] = df_tmp[['NIT9', 'NUMERODEEMPLEADOS', 'GANANCIASDESPUESDEIMPUESTOS', 'TOTALINGRESOOPERATIVO', 'ACTIVOSTOTALES', 'EDAD', 'MES_OFERTA', 'ACTIVIDADES', 'TAMANOEMPRESA', 'FORMALEGAL', 'TOTALDEPATRIMONIO']]

        # Forma legal  ['SAS', 'LTDA', 'SA', 'ESAL', 'SUCURSALEXTRANJERA', 'SCA',  'UNDEFINED', 'SCS', 'PERSONANATURAL']
        indf = df_tmp[(df_tmp['FORMALEGAL'] != 'SAS') & (df_tmp['FORMALEGAL'] != 'LTDA') & (df_tmp['FORMALEGAL'] != 'SA') &
                      (df_tmp['FORMALEGAL'] != 'ESAL') & (df_tmp['FORMALEGAL'] != 'SUCURSALEXTRANJERA') & (df_tmp['FORMALEGAL'] != 'SCA') &
                      (df_tmp['FORMALEGAL'] != 'UNDEFINED') & (df_tmp['FORMALEGAL'] != 'SCS') & (df_tmp['FORMALEGAL'] != 'PERSONANATURAL')].index

        df_tmp.loc[indf, 'FORMALEGAL'] = 'UNDEFINED'
        # print(indf)
        if 'FORMALEGAL' in df_tmp.columns:
            for i in df_tmp['FORMALEGAL'].unique():
                col = columns_F[ord_F.index(i)]
                ind = df_tmp[df_tmp['FORMALEGAL'] == i].index
                df_r.loc[ind, col] = 1
            df_r.drop(['FORMALEGAL'], axis=1, inplace=True)

        # Tamaño Empresa
        if 'TAMANOEMPRESA' in df_tmp.columns:
            for i in df_tmp['TAMANOEMPRESA'].unique():
                col = columns_T[ord_T.index(i)]
                ind = df_tmp[df_tmp['TAMANOEMPRESA'] == i].index
                df_r.loc[ind, col] = 1
            df_r.drop(['TAMANOEMPRESA'], axis=1, inplace=True)

        # Mes Oferta
        if 'MES_OFERTA' in df_tmp.columns:
            for i in df_tmp['MES_OFERTA'].unique():
                print(f"mes {i}")
                col = columns_M[ord_M.index(i)]
                ind = df_tmp[df_tmp['MES_OFERTA'] == i].index
                df_r.loc[ind, col] = 1
            df_r.drop(['MES_OFERTA'], axis=1, inplace=True)

        # Actividad
        if 'ACTIVIDADES' in df_tmp.columns:
            for i in df_tmp['ACTIVIDADES'].unique():
                col = columns_A[ord_A.index(i)]
                ind = df_tmp[df_tmp['ACTIVIDADES'] == i].index
                df_r.loc[ind, col] = 1
            # df_r.drop(['ACTIVIDADES'], axis=1, inplace=True) ------------------------------------------------------------------------- 444

        df_r.fillna(0, inplace=True)
        return df_r

        ######## CLASIFICADORES ########
    def Cla1_predict(self, df1):
        X_test = df1.copy()

        cols = ['NUMERODEEMPLEADOS', 'TOTALDEPATRIMONIO', 'TOTALINGRESOOPERATIVO', 'ACTIVOSTOTALES', 'CONSPROM',
                'F0', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6',
                'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'M10', 'M11', 'M12',
                'A0', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8',
                'T0', 'T1', 'T2']  # 'GANANCIASDESPUESDEIMPUESTOS', 'EDAD',

        X_test = X_test.loc[:, cols].copy()

        X_test.reset_index(inplace=True, drop=True)
        path = 'models/Cla1_Aum_Carg_Red_elec_balanced_v1.pkl'
        my_model_loaded = joblib.load(path)           # Carga del modelo

        X_u = my_model_loaded.named_steps['columntransformer'].transform(
            X_test)  # estandarizo X_test
        scores = my_model_loaded.named_steps['onevsoneclassifier'].decision_function(
            X_u)  # scores de predicción
        # Convierto scores aprobabilidades
        probabilidades = np.exp(
            scores)/np.sum(np.exp(scores), axis=1, keepdims=True)

        return probabilidades  # predict_proba

    def Cla_12_predict(self, df_12):     # CLA1 SIN CONSPROM
        X_test = df_12.copy()
        X_test = X_test.loc[:, ['NUMERODEEMPLEADOS', 'TOTALDEPATRIMONIO', 'TOTALINGRESOOPERATIVO',
                                'F0', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8',
                                'A0', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8',
                                'ACTIVOSTOTALES']].copy()

        X_test.reset_index(inplace=True, drop=True)
        path = 'models/Cla1-2_Aum_Carg_Red_elec_balanced_v2.pkl'  # sin consprom
        my_model_loaded = joblib.load(path)           # Carga del modelo

        X_u = my_model_loaded.named_steps['columntransformer'].transform(
            X_test)  # estandarizo X_test
        scores = my_model_loaded.named_steps['onevsoneclassifier'].decision_function(
            X_u)  # scores de predicción
        # Convierto scores aprobabilidades
        probabilidades = np.exp(
            scores)/np.sum(np.exp(scores), axis=1, keepdims=True)

        return probabilidades  # predict_proba

    def Cla2_predict(self, df2):
        X_test = df2.copy()
        X_test = X_test[['NUMERODEEMPLEADOS', 'TOTALDEPATRIMONIO', 'TOTALINGRESOOPERATIVO', 'ACTIVOSTOTALES',
                         'F0', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7',
                         'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'M10', 'M11', 'M12',
                         'A0', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8']]

        X_test.reset_index(inplace=True, drop=True)
        path = 'models/Cla2_Mant_Cuentas_Ilum_FibraO.pkl'
        my_model_loaded = joblib.load(path)  # Carga mdelo

        X_u = my_model_loaded.named_steps['columntransformer'].transform(
            X_test)  # estandarizo X_test
        scores = my_model_loaded.named_steps['onevsoneclassifier'].decision_function(
            X_u)  # scores de predicción
        # Convierto scores aprobabilidades
        probabilidades = np.exp(
            scores)/np.sum(np.exp(scores), axis=1, keepdims=True)

        return probabilidades  # predict_proba

    def Cla3_predict(self):
        X_test, df_con_nulls = self.transform_load()
        X_test = X_test[['NUMERODEEMPLEADOS', 'TOTALDEPATRIMONIO', 'TOTALINGRESOOPERATIVO', 'ACTIVOSTOTALES', 'EDAD', 'GANANCIASDESPUESDEIMPUESTOS',
                         'T0', 'T1', 'T2',
                         'F0', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7',
                         'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'M10', 'M11', 'M12',
                         'A0', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8']]
        X_test.reset_index(inplace=True, drop=True)
        path = '/content/drive/MyDrive/ENEL X/Codes/Enel_X/Pruebas_03_Abril/Models/Cla3_DDV_PV.pkl'
        my_model_loaded = joblib.load(path)  # Carga mdelo

        return my_model_loaded.predict_proba(X_test)  # predict_proba

    def rango_proba(self, g):  # ------------------------------------- ETIQUETAR PROBABILIDADES  ------------------------------------------------------
        if g < 0.4:
            return 'Baja'  # 'Menor a 40%'#

        if (g >= 0.4) & (g < 0.65):
            return 'Alta'  # 'Entre 40% y 60%' #

        if (g >= 0.65):
            return 'Media'  # 'Mayor a 60%' #

    def etiquetar_rangos(self, pr):
        df_c = pr.copy()

        def n(x): return self.rango_proba(x)
        # n = lambda x:  self.rango_proba(x)

        # print(df_c.columns)
        s1 = pd.DataFrame(df_c['AUMENTOS_CARGA'].apply(n))  # --
        ind = s1[~s1['AUMENTOS_CARGA'].isnull()].index
        df_c.loc[ind, 'R.AUMENTOS_CARGA'] = s1.loc[ind, 'AUMENTOS_CARGA']
        # df_c.loc[ind, 'P.AUMENTOS_CARGA'] = df_c.loc[ind, 'AUMENTOS_CARGA']       # probas

        s1 = pd.DataFrame(df_c['CUENTASNUEVAS'].apply(n))  # --
        ind = s1[~s1['CUENTASNUEVAS'].isnull()].index
        df_c.loc[ind, 'R.CUENTASNUEVAS'] = s1.loc[ind, 'CUENTASNUEVAS']

        s1 = pd.DataFrame(df_c['INSTALACIONES'].apply(n))
        ind = s1[~s1['INSTALACIONES'].isnull()].index
        df_c.loc[ind, 'R.INSTALACIONES'] = s1.loc[ind, 'INSTALACIONES']

        s1 = pd.DataFrame(df_c['REDESELECTRICAS'].apply(n))
        ind = s1[~s1['REDESELECTRICAS'].isnull()].index
        df_c.loc[ind, 'R.REDESELECTRICAS'] = s1.loc[ind, 'REDESELECTRICAS']

        s1 = pd.DataFrame(df_c['MANTENIMIENTO'].apply(n))
        ind = s1[~s1['MANTENIMIENTO'].isnull()].index
        df_c.loc[ind, 'R.MANTENIMIENTO'] = s1.loc[ind, 'MANTENIMIENTO']

        s1 = pd.DataFrame(df_c['ESTUDIOS'].apply(n))  # --
        ind = s1[~s1['ESTUDIOS'].isnull()].index
        df_c.loc[ind, 'R.ESTUDIOS'] = s1.loc[ind, 'ESTUDIOS']

        s1 = pd.DataFrame(df_c['FIBRA_OPTICA'].apply(n))  # --
        ind = s1[~s1['FIBRA_OPTICA'].isnull()].index
        df_c.loc[ind, 'R.FIBRA_OPTICA'] = s1.loc[ind, 'FIBRA_OPTICA']

        s1 = pd.DataFrame(df_c['ILUMINACION'].apply(n))  # --
        ind = s1[~s1['ILUMINACION'].isnull()].index
        df_c.loc[ind, 'R.ILUMINACION'] = s1.loc[ind, 'ILUMINACION']

        return df_c

# ------------------------------------------------------ PREDICCION  ------------------------------------------------------
    def predict_proba(self):

        df_code = self.Encoder()
        df_i = self.df_in.copy()

        df_code.reset_index(drop=True, inplace=True)
        df_i.reset_index(drop=True, inplace=True)

        if 'CONSPROM' in list(df_i.columns):
            # Contiene nulos o ceros en CONSPROM
            if (df_i['CONSPROM'].isna().sum() > 0) | ((df_i['CONSPROM'] == 0).sum() > 0):
                df_CONSPROM = df_code[(df_code['CONSPROM'] != 0) & (
                    df_code['CONSPROM'].notna())]  # con CONSPROM diferente 0 y vacio
                df_sin_CONSPROM = df_code[(df_code['CONSPROM'] == 0) | (
                    df_code['CONSPROM'].isna())]  # SIN CONSPROM
                # print(df_CONSPROM.shape,df_sin_CONSPROM.shape)

                if df_CONSPROM.shape[0] > 0:
                    probas1 = self.Cla1_predict(df_CONSPROM)
                    df_i.loc[df_CONSPROM.index, [
                        'AUMENTOS_CARGA', 'ESTUDIOS', 'INSTALACIONES', 'REDESELECTRICAS']] = probas1

                if df_sin_CONSPROM.shape[0] > 0:
                    probas1_2 = self.Cla_12_predict(df_sin_CONSPROM)
                    df_i.loc[df_sin_CONSPROM.index, [
                        'AUMENTOS_CARGA', 'ESTUDIOS', 'INSTALACIONES', 'REDESELECTRICAS']] = probas1_2

                probas2 = self.Cla2_predict(df_code)
                df_i.loc[df_code.index, ['CUENTASNUEVAS', 'FIBRA_OPTICA',
                                         'ILUMINACION', 'MANTENIMIENTO']] = probas2

            else:  # No nullos ni ceros en CONSPROM
                probas1 = self.Cla1_predict(df_code)
                df_i.loc[:, ['AUMENTOS_CARGA', 'ESTUDIOS',
                             'INSTALACIONES', 'REDESELECTRICAS']] = probas1

                probas2 = self.Cla2_predict(df_code)
                df_i.loc[:, ['CUENTASNUEVAS', 'FIBRA_OPTICA',
                             'ILUMINACION', 'MANTENIMIENTO']] = probas2

        # df_r[['DDV', 'PV']] = probas3
        else:    # No CONSPROM
            probas1 = self.Cla_12_predict(df_code)
            probas2 = self.Cla2_predict(df_code)
            # probas3 = self.Cla3_predict(df_code)

            df_i.loc[:, ['AUMENTOS_CARGA', 'ESTUDIOS',
                         'INSTALACIONES', 'REDESELECTRICAS']] = probas1
            df_i.loc[:, ['CUENTASNUEVAS', 'FIBRA_OPTICA',
                         'ILUMINACION', 'MANTENIMIENTO']] = probas2
            # df_i[['DDV', 'PV']] = probas3

        cols_producto = ['AUMENTOS_CARGA', 'ESTUDIOS', 'INSTALACIONES', 'REDESELECTRICAS',
                         'CUENTASNUEVAS', 'FIBRA_OPTICA', 'ILUMINACION', 'MANTENIMIENTO']
        df_r = df_i[cols_producto].copy()
        df_i.drop(cols_producto, axis=1, inplace=True)

        # df_probabilidades_tmp = df_r.copy() ##################################----------------

        lista = []
        for i in range(len(df_r)):
            df_concat = df_r.loc[i, :].sort_values(ascending=False).keys()
            lista.append(df_concat)
        rank = pd.DataFrame(lista, columns=[1, 2, 3, 4, 5, 6, 7, 8])

        # df_rank_tmp = rank.copy()##################################----------------

        probas_rangos = self.etiquetar_rangos(df_r)

        df_re = pd.DataFrame()
        for j in range(rank.shape[1]):
            df_re.loc[:, 'Producto_'+str(j+1)] = rank.iloc[:, j]

            for i in range(len(rank)):
                p = rank.iloc[i, j]
                campo = 'R.' + p
                # Agregar los rangos de probabilidad
                df_re.loc[i, 'Probabilidad_' +
                          str(j+1)] = probas_rangos.loc[i, campo]
                # Agregar los rangos de probabilidad
                df_re.loc[i, 'Valor_probabilidad' +
                          str(j+1)] = probas_rangos.loc[i, p]

            # ## ----- Agg probas
            # for i in range(len(rank)):
            #   p = rank.iloc[i,j]
            #   campo = 'P.'+ p
            #   df_re.loc[i,'Probabilidad '+str(j+1)]=probas_rangos.loc[i,campo]    # Agregar las probabilidades

        return probas_rangos, pd.concat([df_i, df_re], axis=1)  # df_i

# ------------------------------------------------------ VALIDACIONES  ------------------------------------------------------

    def ValidarCamposCartera(self):
        df_sin_nulls, df_f = self.transform_load()

        dic = {'RANGOCONSUMO': 'O', 'RANGODECOMPRA($)': 'O', 'RANGORECURRENCIACOMPRA': 'O',
               'CLUSTERCOMPRADOS': 'O', 'TIPOCLIENTE#OPORTUNIDADES': 'O', 'TIPOCLIENTE$OPORTUNIDADES': 'O',
               'CATEGORIZACIONSECTORES': 'O', 'ESTATUSOPERACIONAL': 'O', 'TAMANOEMPRESA': 'O',
               'CATEGORIADEPARTAMENTO': 'O', 'DEPARTAMENTO': 'O', 'OPORTUNIDADESVENDIDAS': 'int', 'OPORTUNIDADESCOTIZADAS($)': 'float'}
        campos = []
        existe = []
        dtype_corr = []
        tipo = []

        for campo in dic.keys():
            campos.append(campo)
            if campo in df_f.columns.to_list():  # Si el campo está en la base
                existe.append('SI')
                dtype_corr.append(dic[campo])
                if df_f[campo].dtype == dic[campo]:  # Si el tipo de campo es el indicado
                    tipo.append('OK')
                else:
                    tipo.append('Validar')
            else:                             # Si el campo no se encuentra en la base
                existe.append('NO')
                dtype_corr.append(dic[campo])
                tipo.append('Validar')

        return pd.DataFrame({'CAMPO': campos,
                             'EXISTE': existe,
                             'TIPO': tipo,
                             'TIPO_CORRECTO': dtype_corr})

    def ValidarCamposModelo(self):
        df_sin_nulls, df_f = self.transform_load()

        dic = {'NUMERODEEMPLEADOS': 'int',
               'GANANCIASDESPUESDEIMPUESTOS': 'float',
               'TOTALINGRESOOPERATIVO': 'float',
               'ACTIVOSTOTALES': 'float',
               'FECHACONSTITUCION': 'datetime64[ns]',
               'CONSPROM': 'float',
               'ACTIVIDADPRINCIPAL(EMIS)': 'O',
               'TAMANOEMPRESA': 'O',
               'FORMALEGAL': 'O',
               'TOTALDEPATRIMONIO': 'float'
               }

        campos = []
        existe = []
        dtype_corr = []
        tipo = []

        for campo in dic.keys():
            campos.append(campo)
            if campo in df_f.columns.to_list():
                existe.append('SI')
                dtype_corr.append(dic[campo])
                if df_f[campo].dtype == dic[campo]:
                    if campo == 'NUMERODEEMPLEADOS' and (df_f['NUMERODEEMPLEADOS'] < 0).sum() > 0:
                        tipo.append('Validar negativos no permitidos')
                    else:
                        tipo.append('OK')
                else:
                    if campo != 'NUMERODEEMPLEADOS':
                        tipo.append('Validar')
                    else:
                        tipo.append('OK')
            else:
                existe.append('NO')
                dtype_corr.append(dic[campo])
                tipo.append('Validar')

        return pd.DataFrame({'CAMPO': campos,
                             'EXISTE': existe,
                             'TIPO': tipo,
                             'TIPO_CORRECTO': dtype_corr})

    def Validar_categorias_por_campo(self):

        df_sin_nulls, dft = self.transform_load()
        m_DIC = {'RANGOCONSUMO': ['SINCATALOGAR', 'ENTRE10000Y55000', 'MENORA5000', 'ENTRE5000Y10000', 'MAYORA55000'],
                 'RANGODECOMPRA($)': ['SINCATALOGAR', 'NOCOMPRADOR', 'PEQUENOCOMPRADOR', 'MEDIANOCOMPRADOR', 'GRANCOMPRADOR', 'COMPRADORMEGAPROYECTOS'],
                 'RANGORECURRENCIACOMPRA': ['SINCATALOGAR', 'NOCOMPRADOR', 'UNICACOMPRA', 'BAJARECURRENCIA', 'RECURRENCIAMEDIA', 'GRANRECURRENCIA'],
                 'CLUSTERCOMPRADOS': ['SINCATALOGAR', 'NOCOMPRADOR', 'COMPRADOR1CLUSTER', 'COMPRADOR2CLUSTER'],
                 'TIPOCLIENTE#OPORTUNIDADES': ['SINCATALOGAR', 'NICOMPRA-NICOTIZA', 'SOLOCOTIZAN', 'COTIZANMASDELOQUECOMPRAN',
                                               'COMPRANYCOTIZAN', 'COMPRANMASDELOQUECOTIZAN', 'SIEMPRECOMPRAN'],
                 'TIPOCLIENTE$OPORTUNIDADES': ['SINCATALOGAR', 'NICOMPRA-NICOTIZA', 'SOLOCOTIZAN', 'COTIZANMASDELOQUECOMPRAN',
                                               'COMPRANYCOTIZAN', 'COMPRANMASDELOQUECOTIZAN', 'SIEMPRECOMPRAN'],
                 'CATEGORIZACIONSECTORES': ['SINCATALOGAR', 'OTROSSECTORES', 'SECTORALTOVALOR'],
                 'ESTATUSOPERACIONAL': ['NOSECONOCEELESTATUS', 'BAJOINVESTIGACIONLEGAL', 'OPERACIONAL'],
                 'TAMANOEMPRESA': ['SINCATALOGAR', 'PEQUENAEMPRESA', 'MEDIANAEMPRESA', 'GRANEMPRESA'],
                 'CATEGORIADEPARTAMENTO': ['NOSECONOCEELDEPARTAMENTO', 'OTROSDEPARTAMENTOS', 'COSTA', 'CUNDINAMARCA', 'BOGOTADC'],

                 'DEPARTAMENTO': ['AMAZONAS', 'ANTIOQUIA', 'ARAUCA', 'ATLANTICO', 'BOGOTADC', 'BOLIVAR', 'BOYACA', 'CALDAS', 'CAQUETA', 'CASANARE', 'CAUCA', 'CESAR',
                                  'CHOCO', 'CORDOBA', 'CUNDINAMARCA', 'GUAINIA', 'GUAVIARE', 'HUILA', 'LAGUAJIRA', 'MAGDALENA', 'META', 'NARINO', 'NORTEDESANTANDER',
                                  'PUTUMAYO', 'QUINDIO', 'RISARALDA', 'SANANDRESYPROVIDENCIA', 'SANTANDER', 'SUCRE', 'TOLIMA', 'VALLEDELCAUCA', 'VAUPES', 'VICHADA'],

                 'FORMALEGAL': ['SAS', 'LTDA', 'SA', 'ESAL', 'SUCURSALEXTRANJERA', 'SCA', 'UNDEFINED', 'SCS', 'PERSONANATURAL']
                 }

        campos = []
        valido = []
        detalle = []
        recomendacion = []

        if 'FORMALEGAL' in dft.columns:
            # Forma legal  ['SAS', 'LTDA', 'SA', 'ESAL', 'SUCURSALEXTRANJERA', 'SCA',  'UNDEFINED', 'SCS', 'PERSONANATURAL']
            indf = dft[(dft['FORMALEGAL'] != 'SAS') & (dft['FORMALEGAL'] != 'LTDA') & (dft['FORMALEGAL'] != 'SA') &
                       (dft['FORMALEGAL'] != 'ESAL') & (dft['FORMALEGAL'] != 'SUCURSALEXTRANJERA') & (dft['FORMALEGAL'] != 'SCA') &
                       (dft['FORMALEGAL'] != 'UNDEFINED') & (dft['FORMALEGAL'] != 'SCS') & (dft['FORMALEGAL'] != 'PERSONANATURAL')].index

            dft.loc[indf, 'FORMALEGAL'] = 'UNDEFINED'

        for i in list(m_DIC.keys()):      # Encontrar categorias
            nofound = []
            campos.append(i)
            if i in dft.columns:
                for j in dft[i].unique():
                    if j in list(m_DIC[i]):
                        pass
                    else:
                        nofound.append(j)

                if len(nofound) == 0:               # Si todas se encuentran
                    valido.append('SI')
                    detalle.append('OK')
                    recomendacion.append('OK')

                else:  # Si no se encuentra al menos una
                    valido.append('NO')
                    detalle.append(str(nofound))
                    recomendacion.append('Validar')

            else:
                valido.append('NO')
                detalle.append("Validar")  # nofound
                recomendacion.append('Validar')

        # print(len(campos),len(valido))
        # print('\n', valido)
        return pd.DataFrame({'CAMPO': campos,
                             'CATEGORIAS_VALIDAS': valido,
                             'DETALLE_CATEGORIAS': detalle,
                             'RECOMENDACION_CATEGORIAS': recomendacion})

    def Validar_todo(self):
        # df_report_types = self.validar_dtypes()
        df_report_campos = pd.concat([self.ValidarCamposCartera(
        ), self.ValidarCamposModelo()]).reset_index(drop=True)

        e_existe = np.array(
            df_report_campos[df_report_campos['CAMPO'] == 'ACTIVIDADPRINCIPAL(EMIS)']['EXISTE'])
        e_tipo = np.array(
            df_report_campos[df_report_campos['CAMPO'] == 'ACTIVIDADPRINCIPAL(EMIS)']['TIPO'])

        # print('booleanos: ', e_existe,e_tipo)
        if e_existe == 'SI' and e_tipo == 'OK':
            tmp_A = self.Agrupar_actividades('ACTIVIDADPRINCIPAL(EMIS)')
            num_no_agrupados = (tmp_A['ACTIVIDADES']
                                == 'Actividad_Desconocida').sum()

            df_validar_cat = self.Validar_categorias_por_campo()
            df_validar_cat.index = df_validar_cat['CAMPO']
            df_validar_cat.drop('CAMPO', axis=1, inplace=True)

            if num_no_agrupados > 0:
                df_validar_cat.loc['ACTIVIDADPRINCIPAL(EMIS)', 'CATEGORIAS_VALIDAS'] = str(
                    num_no_agrupados)+' Actividades no fueron agrupadas y no se les dará recomendación '
                if tmp_A.shape[0] <= num_no_agrupados:
                    text = 'No hay registros aptos para recomendar.'
                    flag_A = False
                elif ((tmp_A.shape[0] - num_no_agrupados) > 1):
                    text = 'Registros aptos para recomendar: ' + \
                        str(tmp_A.shape[0]-num_no_agrupados)
                    flag_A = True
        else:
            df_validar_cat = self.Validar_categorias_por_campo()
            df_validar_cat.index = df_validar_cat['CAMPO']
            df_validar_cat.drop('CAMPO', axis=1, inplace=True)

        text = 'Registros aptos para recomendar: ' + \
            str(tmp_A.shape[0]-num_no_agrupados)
        flag_A = True

        df_v = pd.merge(df_report_campos, df_validar_cat,
                        how='outer', on='CAMPO').fillna('No aplica')
        df_v.drop(8, axis=0, inplace=True)
        df_v.reset_index(drop=True, inplace=True)
        # Predecir o no?

        bool_tipo = 'Validar' not in df_v['TIPO'].unique()
        bool_existe = 'NO' not in df_v['EXISTE'].unique()
        bool_cat = 'NO' not in df_v['CATEGORIAS_VALIDAS'].unique()

        final_flag = flag_A and bool_tipo and bool_existe and bool_cat

        return df_v, text, final_flag

    # -- 06/06/2023 --
    ## -------------------------------------------------------------------- LOGS  -------------------------------------------------------------------------  ##

    def validar_categorias(self, dataframe, campo, categorias_posibles):
        indices_categorias_distintas = []
        indices_categorias_posibles = []
        categorias_incorrectas = []

        dataframe.replace({'NAN': np.nan,
                           'nan': np.nan}, inplace=True)

        lista_campos = []
        for co_e in dataframe.columns:
            if co_e in ['NIT9', 'NUMERODEEMPLEADOS', 'TOTALINGRESOOPERATIVO', 'TAMANOEMPRESA', 'GANANCIASDESPUESDEIMPUESTOS', 'ACTIVOSTOTALES', 'TOTALDEPATRIMONIO',
                        'FORMALEGAL',    'FECHACONSTITUCION',     'ACTIVIDADES', 'DEPARTAMENTO', 'OPORTUNIDADESVENDIDAS', 'OPORTUNIDADESCOTIZADAS($)']:

                lista_campos.append(co_e)

        dataframe = self.eliminar_registros_vacios(dataframe, lista_campos)

        # dataframe = dataframe.reset_index(drop=True)

        for index, row in dataframe[lista_campos].iterrows():
            # Verifica si algún campo contiene el string 'NAN'
            if 'NAN' in row.values:
                # print(row.values)
                # Elimina el registro correspondiente
                dataframe = dataframe.drop(index)

        # dataframe = dataframe.dropna()
        dataframe = self.eliminar_registros_vacios(dataframe, lista_campos)

        for i, categoria in zip(dataframe.index, dataframe[campo]):
            if (categoria not in categorias_posibles) & (categoria != np.nan) & (categoria != 'NAN') & (categoria != 'nan'):
                indices_categorias_distintas.append(i)
                categorias_incorrectas.append(categoria)
            else:
                indices_categorias_posibles.append(i)

        return indices_categorias_distintas, indices_categorias_posibles, categorias_incorrectas

    def obtener_hora_fecha(self):
        # Obtener la fecha y hora actual en la zona horaria UTC
        now_utc = datetime.now(pytz.utc)

        # Obtener la zona horaria de Colombia
        colombia_tz = pytz.timezone('America/Bogota')

        # Convertir la hora de UTC a la zona horaria de Colombia
        now_colombia = now_utc.astimezone(colombia_tz)

        # Formatear la fecha y hora en el formato deseado
        formatted_datetime = now_colombia.strftime("%H:%M:%S %d/%m/%Y")

        return formatted_datetime

    def contar_registros_por_tipo(self, df, columna, tipo_dato):
        # Lista para almacenar los índices de los registros incorrectos
        indices_incorrectos = []

        # Lista para almacenar los índices de los registros correctos
        indices_correctos = []
        # print(columna,' ',str(df[columna].dtype))
        # Iterar sobre los valores de la columna en el DataFrame y obtener su índice
        for indice, valor in enumerate(df[columna]):
            # Verificar si el valor es una instancia del tipo de dato correcto

            if columna == 'NUMERODEEMPLEADOS':
                if valor % 1 != 0:
                    val_float = True
                else:
                    val_float = False
            else:
                val_float = False

            if (val_float == False) & (isinstance(valor, np.dtype(tipo_dato).type)):
                # Si es correcto, agregar el índice a la lista de registros correctos
                indices_correctos.append(indice)
            elif val_float:
                # Si no es correcto, agregar el índice a la lista de registros incorrectos
                indices_incorrectos.append(indice)

        # Devolver las listas de índices
        return indices_incorrectos, indices_correctos

    # ------------------------------------------------------------------------------------------------ 14/06/2023

    def obtener_registros_vacios(self, df):
        # Obtener la lista de nombres de columnas
        columnas = df.columns.tolist()

        # Inicializar listas para almacenar la información de cada columna
        nombre_campo = []
        registros_vacios = []
        indices_vacios = []

        # Iterar sobre cada columna del DataFrame
        for columna in columnas:
            # Obtener los índices de los registros vacíos en la columna actual
            indices = df[df[columna].isnull()].index.tolist()

            # Agregar información a las listas correspondientes si hay registros vacíos
            if indices:
                nombre_campo.append(columna)
                registros_vacios.append(len(indices))
                indices_vacios.append(indices)

        # Convertir las listas en una cadena separada por comas
        indices_vacios = [','.join(map(str, indices))
                          for indices in indices_vacios]

        # Crear un nuevo DataFrame con la información recopilada
        df_resultado = pd.DataFrame({'Nombre campo': nombre_campo,
                                    'Registros vacíos': registros_vacios,
                                     'Índices de los registros vacíos': indices_vacios})

        return df_resultado

    # ------------------------------------------------------------------------------------------------

    def Logs(self):

        lista_logs = []
        logs_riesgo = []

        df_v, text, final_flag = self.Validar_todo()

        # Campos faltantes:
        campos_faltantes = list(df_v[df_v['EXISTE'] == 'NO']['CAMPO'])

        # print(len(campos_faltantes))
        # Tipo de dato incorrecto en los campos: Entrar a validar ¿cuantos registros?
        campos_tipo_incorrecto = df_v[(df_v['TIPO'] == 'Validar') & (
            df_v['EXISTE'] != 'NO')]['CAMPO']
        # Tipo correcto
        tipo_correcto = df_v[(df_v['TIPO'] == 'Validar') & (
            df_v['EXISTE'] != 'NO')]['TIPO_CORRECTO']

        # Campos con categorias no esperadas
        m_DIC = {'RANGOCONSUMO': ['SINCATALOGAR', 'ENTRE10000Y55000', 'MENORA5000', 'ENTRE5000Y10000', 'MAYORA55000'],
                 'RANGODECOMPRA($)': ['SINCATALOGAR', 'NOCOMPRADOR', 'PEQUENOCOMPRADOR', 'MEDIANOCOMPRADOR', 'GRANCOMPRADOR', 'COMPRADORMEGAPROYECTOS'],
                 'RANGORECURRENCIACOMPRA': ['SINCATALOGAR', 'NOCOMPRADOR', 'UNICACOMPRA', 'BAJARECURRENCIA', 'RECURRENCIAMEDIA', 'GRANRECURRENCIA'],
                 'CLUSTERCOMPRADOS': ['SINCATALOGAR', 'NOCOMPRADOR', 'COMPRADOR1CLUSTER', 'COMPRADOR2CLUSTER'],
                 'TIPOCLIENTE#OPORTUNIDADES': ['SINCATALOGAR', 'NICOMPRA-NICOTIZA', 'SOLOCOTIZAN', 'COTIZANMASDELOQUECOMPRAN',
                                               'COMPRANYCOTIZAN', 'COMPRANMASDELOQUECOTIZAN', 'SIEMPRECOMPRAN'],
                 'TIPOCLIENTE$OPORTUNIDADES': ['SINCATALOGAR', 'NICOMPRA-NICOTIZA', 'SOLOCOTIZAN', 'COTIZANMASDELOQUECOMPRAN',
                                               'COMPRANYCOTIZAN', 'COMPRANMASDELOQUECOTIZAN', 'SIEMPRECOMPRAN'],
                 'CATEGORIZACIONSECTORES': ['SINCATALOGAR', 'OTROSSECTORES', 'SECTORALTOVALOR'],
                 'ESTATUSOPERACIONAL': ['NOSECONOCEELESTATUS', 'BAJOINVESTIGACIONLEGAL', 'OPERACIONAL'],
                 'TAMANOEMPRESA': ['SINCATALOGAR', 'PEQUENAEMPRESA', 'MEDIANAEMPRESA', 'GRANEMPRESA'],
                 'CATEGORIADEPARTAMENTO': ['NOSECONOCEELDEPARTAMENTO', 'OTROSDEPARTAMENTOS', 'COSTA', 'CUNDINAMARCA', 'BOGOTADC'],
                 #  'ACTIVIDADES'               :['INDUSTRIAL', 'SERVICIOS', 'TRANSPORTE', 'COMERCIO', 'ENERGETICO',
                 #                               'FINANCIERO', 'CONSTRUCCION', 'COMUNICACIONES', 'AGROPECUARIO'],
                 'DEPARTAMENTO': ['AMAZONAS', 'ANTIOQUIA', 'ARAUCA', 'ATLANTICO', 'BOGOTADC', 'BOLIVAR', 'BOYACA', 'CALDAS', 'CAQUETA', 'CASANARE', 'CAUCA', 'CESAR',
                                  'CHOCO', 'CORDOBA', 'CUNDINAMARCA', 'GUAINIA', 'GUAVIARE', 'HUILA', 'LAGUAJIRA', 'MAGDALENA', 'META', 'NARINO', 'NORTEDESANTANDER',
                                  'PUTUMAYO', 'QUINDIO', 'RISARALDA', 'SANANDRESYPROVIDENCIA', 'SANTANDER', 'SUCRE', 'TOLIMA', 'VALLEDELCAUCA', 'VAUPES', 'VICHADA'],

                 'FORMALEGAL': ['SAS', 'LTDA', 'SA', 'ESAL', 'SUCURSALEXTRANJERA', 'SCA', 'UNDEFINED', 'SCS', 'PERSONANATURAL']
                 }

        if len(campos_faltantes) > 0:
            legend_campos_faltantes = str(self.obtener_hora_fecha(
            ))+' - ' + 'En la tabla cargada no se encuentran algunas columnas necesarias: ' + ', '.join(map(str, campos_faltantes))  # str(campos_faltantes)
            lista_logs.append(legend_campos_faltantes)
            logs_riesgo.append('1')
            # print('flag1')

        # Conteo de registros con tipo de dato correcto e incorrecto

        for campo, tipo in zip(campos_tipo_incorrecto, tipo_correcto):  # Valido dtypes
            if tipo == 'O':
                tipo = str
            else:
                pass

            ind_tipo_incorrecto, ind_tipo_correcto = self.contar_registros_por_tipo(
                self.transform_load()[0], campo, tipo)

            # df_apto = df_v.loc[ind_tipo_correcto,:].copy()
            dft, df_con_nulls = self.transform_load()
            df_apto = dft.iloc[ind_tipo_correcto, :].copy()
            # df_no_apto = df_v.loc[ind_tipo_incorrecto,:].copy()
            df_no_apto = dft.iloc[ind_tipo_incorrecto, :].copy()

            # LOG -------------------------------------------------------------------------------
            #
            # Legends conteos
            # legend_registros_aptos = str(self.obtener_hora_fecha())+' - '+str(len(df_apto))+' registros aptos para recomendar.'
            if len(df_no_apto) > 0:
                legend_registros_malos = str(self.obtener_hora_fecha())+' - '+'En la columna '+str(
                    campo) + ' se encontraron '+str(len(df_no_apto))+' valores que no son del tipo esperado ('+str(tipo)+').'
            # legend_categorias_malas = str(self.obtener_hora_fecha())+' - '+'En el campo '+str(campo)+ ' se encontraron '+str(len(cat_no_esperadas))+' categorias no esperadas: '+str(cat_no_esperadas)
                lista_logs.append(legend_registros_malos)
                logs_riesgo.append(0)
                # print('flag2')
            # lista_logs.append(legend_categorias_malas)

            # lista_logs.append(legend_registros_aptos)legend_categorias_malas

        # ---------------------------------------------------------------------------------------- 14/06/2023

        df_transformado, df_con_nulls = self.transform_load()
        df_con_nulls.replace({'NAN': np.nan}, inplace=True)

        campos_existentes = list(df_v[df_v['EXISTE'] == 'SI']['CAMPO'])
        campos_existentes = ['NIT9']+campos_existentes

        df_campos_existentes = df_con_nulls[campos_existentes].copy()

        num_reg_con_vacios = df_campos_existentes.isna().sum().sum()

        # print(df_campos_existentes.isna().sum())

        if num_reg_con_vacios > 0:
            df_conteo_reg_vacios = self.obtener_registros_vacios(
                df_campos_existentes)
            cc = 0
            for campo, conteo, indices in zip(df_conteo_reg_vacios['Nombre campo'], df_conteo_reg_vacios['Registros vacíos'], df_conteo_reg_vacios['Índices de los registros vacíos']):
                print(len(df_conteo_reg_vacios['Nombre campo']))
                mask_logs = ['CLIENTES_CON_PRODUCTO', 'FRECUENCIA_DE_CONTACTO', 'NIVEL_EDUCATIVO',
                             'SITUACION_LABORAL', 'FECHA_NACIMIENTO', 'CIUDAD', 'DEPARTAMENTO']
                print(len(mask_logs), cc)
                legend_reg_campos_vacios = str(self.obtener_hora_fecha())+' - '+'En la columna '+str(
                    mask_logs[cc]) + ' se encontraron '+str(conteo)+' registros con campos vacios en las filas: '+str(indices)+'.'
                lista_logs.append(legend_reg_campos_vacios)
                logs_riesgo.append(0)
                cc += 1
            # --------------------------------------------------------------------------------------

        campos_categorias_no_esperadas = list(df_v[(df_v['CATEGORIAS_VALIDAS'] == 'NO') & (
            df_v['EXISTE'] != 'NO')]['CAMPO'])  # [df_v['EXISTE']!='NO']['CAMPO'])
        # print('flag3')

        dff = self.transform_load()[0]
        # print(dff.isna().sum())

        indices_correctos = set()
        for campo in campos_categorias_no_esperadas:
            # print(campo)
            indices_distintos, indices_posibles, categorias_incorrectas = self.validar_categorias(
                dff, campo, m_DIC[campo])
            indices_correctos.update(indices_posibles)
            # Convertir la lista a un conjunto para eliminar elementos duplicados
            conjunto = set(categorias_incorrectas)
            # Convertir el conjunto nuevamente en una lista
            categorias_incorrectas = list(conjunto)

            if len(indices_distintos) > 0:
                legend_categorias_malas = str(self.obtener_hora_fecha())+' - '+'En la columna FRECUENCIA_DE_CONTACTO se encontraron '+str(len(indices_distintos)) + \
                    ' registros con categorias no esperadas: ' + \
                    ', '.join(map(str, categorias_incorrectas)) + \
                    ' en las filas '+', '.join(map(str, indices_distintos))
                lista_logs.append(legend_categorias_malas)
                logs_riesgo.append(0)
        # print('flag4')

        self.df_in = self.df_in.loc[list(
            indices_correctos), :].reset_index(drop=True)

        return lista_logs, logs_riesgo, list(indices_correctos)

    # ----------------------------------------------------------------------------------------------

    def generar_graficos_pie(self, configuraciones, mayus=True, paleta=1, width=600, height=400):

        df_t, _ = self.transform_load()
        for config in configuraciones:
            df_group = df_t.groupby(by=config['groupby'], as_index=True)[
                'NIT9'].count()
            df_group = pd.DataFrame(df_group)
            # st.write(df_group)

            if mayus == True:
                # Reordenar el DataFrame según el orden deseado
                df_group = df_group.reindex(config['order'])
            else:
                # Ordenar de mayor a menor
                df_group.sort_values(by='NIT9', ascending=False, inplace=True)

            # Extrae indice a columna
            df_group.reset_index(inplace=True, drop=False)
            df_group.dropna(inplace=True)
            df_group.reset_index(inplace=True, drop=True)
            # st.write(df_group)

            df_group.rename(
                {'NIT9': 'Cantidad', config['groupby']: config['y_axis']}, axis=1, inplace=True)
            df_group['Cantidad'] = pd.to_numeric(df_group['Cantidad'])

            if mayus == True:
                keys = config['order']
                values = config['order_f']

                diccionario = dict(zip(keys, values))
                # print('valdiar ',df_group[config['y_axis']])
                df_group[config['y_axis']] = df_group[config['y_axis']
                                                      ].replace(diccionario)

            df_group[config['y_axis']] = pd.Categorical(
                df_group[config['y_axis']], ordered=True)

            df_group['Porcentaje'] = df_group['Cantidad'] / \
                df_group['Cantidad'].sum() * 100
            df_group['Porcentaje'] = df_group['Porcentaje'].round(2)
            df_group['Porcentaje'] = df_group['Porcentaje'].apply(
                lambda x: ' {:.2f}%'.format(x))

            # st.write(df_group)

        ###################################
            labels = df_group[config['y_axis']]
            values = df_group['Cantidad']*100

            if paleta == 1:
                colors = ['#162055', '#0076BA', '#79B4D9', '#DDF2FD', '#0378A6']
            elif paleta == 2:
                colors = ['#162055', '#0076BA', '#79B4D9', '#DDF2FD', '#0378A6']

            colors = colors[:len(df_group)]

            fig = go.Figure(
                data=[go.Pie(labels=labels, values=values, marker=dict(colors=colors))])
            # fig.update_traces(hovertemplate="%{label}<br> %{value}K")
            fig.update_layout(margin=dict(l=0, r=0, t=0, b=0),
                              legend=dict(
                x=-0.5,
                y=0.75,
                xanchor='center',
                yanchor='top',
                # font=dict(size=16  )
            ),
                width=width,  # Ajustar el ancho del gráfico
                height=height  # Ajustar la altura del gráfico
            )

            # config['col'].plotly_chart(fig)
            return fig
